MAST ANALYSIS OF A R AVENSCAR PRECEDENCE - CONSTRAINED APPLICATION WITH FPS AND EDF SCHEDULING

T ECHNICAL R EPORT

Email:

Giovanni Jiayi Hu Department of Mathematics University of Padua, Italy I-35121 giovannijiayi.hu@studenti.unipd.it

Email:

Alessio Gobbo Department of Mathematics University of Padua, Italy I-35121 alessio.gobbo@studenti.unipd.it

March 1, 2020

A BSTRACT

This paper describes a hard real-time application built with the Ravenscar proﬁle of the Ada programming language and running on a real-time kernel of reduced size and complexity. The application is comprised by several tasks whose activation events present dependency relationships and this characteristic allow interesting considerations during the different analysis we provide. We consider the same tasks under both Fixed-Priority Scheduling (FPS) and Earliest Deadline First (EDF) and evaluate different metrics like response times, jitters and blocking times. Throughout the sections, we also test the ability of the MAST analysis tools to describe a formal model of dependent tasks and to check their deadline satisfaction with less pessimism as possible without compromising correctness. Lastly, we offer some insight on the behaviour of both FPS and EDF systems under permanent and transient overload, as showcase of how classic real-time considerations may be revaluated to consider dependent tasks.

1

Introduction

Embedded systems have to satisfy strict timing requirements and especially in the case of such hard real-time applications, predictability of the timing behavior is an extremely important aspect. So it is the choice of a suitable design and development method, in conjunction with supporting tools that enable the real-time performance of a system to be analysed and simulated. The result can lead to a high level of conﬁdence that the ﬁnal system meets its real-time constraints.

As a matter of fact, the use of Ada has proven to be of great value within high integrity and real-time applications, thanks to language subsets of deterministic constructs, to ensure full analysability of the code. In embedded systems, the programmer is tied to become more concerned with the implementation and efﬁcient manipulation of the abstract program entities rappresenting the underlying hardware. Ada solves this issue by i.e. providing the programmer facilities for interrupt handling, access to shared variables and deﬁnition of task attributes.

Notably, the Ravenscar proﬁle [1] is a subset of the tasking model, restricted to meet the real-time community requirements for determinism, schedulability analysis and memory-boundedness, as well as being suitable for mapping to a small and efﬁcient run-time system that supports task synchronization and communication.

Along with the Ravenscar proﬁle, we have used a model for representing the temporal and logical elements of real-time applications, called MAST [4]. This model allows a very rich description of the system, including the effects of event or message-based synchronization, multiprocessor and distributed architectures as well as shared resource synchronization.

The bare-board used throughout our analysis is the STM32F429I-Discovery, a low-cost and easy-to-use development kit to start a development with an STM32F4 microcontroller and equipped with an ARM Cortex-M4 core. The board has been used along with the ravenscar-full-stm32f429disco runtime environment. The runtime implementation is MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

provided by GNAT, a free-software compiler for the Ada language, and it is based upon the Open Ravenscar Real-Time Kernel [3], which provides full conformance with the Ravenscar proﬁle.

We have preferred the usage of a bare-board instead of the GNAT ARM emulator as we have noticed signiﬁcant variance with the execution times measured on the latter. The board also includes a ST-LINK/V2 embedded debug tool, which can halt the processor, insert/remove breakpoints and execute instructions line by line [20].

We shall start the paper assuming Fixed Priority Scheduling (FPS), since its behaviour is more predictable and easier to reason about, and then introduce the Earliest Deadline First (EDF) scheduling by means of their differences.

The rest of the paper is organized as follows. The remaining Section 1 will provide an introduction to the ﬁxed-priority scheduling and analysis, the application under consideration and some general notions of the Ada tasking model. A more formal description of our system is then presented in Section 2, followed by considerations about measuring the execution times and detecting deadline misses in Section 3 and 4 respectively.

Section 5 offers and in-depth description of the MAST model and its available analysis tools. Later, Sections 6 provides the insight of our FPS analysis with both stand-alone tasks and precedence relations, followed by a comparative EDF analysis in Section 7. Lastly, Section 8 includes some considerations of both systems under overload, whereas conclusions are contained in Section 8.

In the next sections whenever we will use the term [RM], we will refer to a section of the Ada Language Reference Manual 1 .

1.1 Fixed-priority scheduling and analysis

In the ﬁxed priority system under analysis, each task is assigned a static priority and the schedule is generated based on the current priority value. According to the Rate Monotonic analysis [11], the ﬁxed priorities are ordered based on the rates, so the task with the smallest period receives the highest priority. The rate (of job releases) of a task is the inverse of its period.

Another well-known ﬁxed-priority algorithm is the Deadline Monotonic algorithm [11]. This algorithm assigns priorities to tasks according their relative deadlines: the shorter the relative deadline, the higher the priority.

Clearly, when the relative deadline of every task is proportional to its period, the two algorithms are identical. When the relative deadlines are arbitrary, the Deadline Monotonic algorithm performs better in the sense that it can sometimes produce a feasible schedule when the Rate Monotonic algorithm fails, while the RM algorithm always fails when the DM algorithm fails.

The schedulability analysis uses as inputs the given tasks of periods T i and execution times C i and checks one task τ i at a time to determine whether the response times of all its jobs are equal to or less than its relative deadline D i .

FPS analysis do not count on any relationship among the release times to hold, and identiﬁes the worst-case combination of release times of any job of task τ i , and all the jobs in the other tasks that have higher priorities. This combination is the worst because the response time of a job released under this condition is the largest possible for all combinations of release times.

This worst-case time instant is called the critical instant and corresponds to when the job is released at the same time with a job in every higher-priority task, e.g. all of the latter tasks are in phase. This is the case where the response time of the task is the largest and the analysis checks if it is still equal to or less than its relative deadline D i .

To determine whether a task can meet all its deadlines, an analysis called time-demand analysis computes the total demand for processor time by a job released at a critical instant of the task and by all the higher-priority tasks as a function of time from the critical instant. It then checks whether this demand can be met before the deadline of the job.

To carry out the time-demand analysis on the taskset, we consider one task at a time, starting from the task τ 1 with the highest priority in order of decreasing priority. Assuming t 0 as the release time of the job from task τ i at the critical instant, at time t 0 + t, for t ≥ 0, the total (processor) time demand w i (t) of this job and all the higher-priority jobs released in [t 0 , t] is given by the following formula for 0 < t ≤ T i

i−1 X

k=1

t

w i (t) = C i +

d

eC k k

T

1

http://www.ada-auth.org/standards/rm12_w_tc1/html/RM-TOC.html

2 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

If w i (t) > t for all 0 < t ≤ D i , this job cannot complete by its deadline. The task τ i , and hence the given system of tasks, cannot be feasibly scheduled by the ﬁxed-priority algorithm.

Time-demand analysis can be usually depicted plotting the time-demand function as in Figure 1.

Figure 1: Time-demand analysis example of four tasks (T, C i ): (3,1), (5, 1.5), (7, 1.25), and (9, 0.5) [11]

1.2 The application

The example application presented in this paper is extracted from "Guide for the use of the Ada Ravenscar Proﬁle in high integrity systems" [1]. It includes a periodic process that handles orders for a variable amount of workload. Whenever the request level exceeds a certain threshold, the periodic process farms the excess load out to a supporting sporadic process. While such orders are executed, the system may receive interrupt requests from an external manual push-button. Each interrupt treatment records an entry in an activation log.

When speciﬁc conditions hold, the periodic process releases a further sporadic process to perform a check on the interrupt activation entries recorded in the intervening period. The policy of work delegation adopted by the system allows the periodic process to ensure the constant discharge of a guaranteed level of workload.

The correct implementation of this policy also requires assigning the periodic process a higher priority than those assigned to the sporadic processes, so that guaranteed work can be performed in preference to subsidiary activities.

The application is comprised by the tasks and attributes in Table 1. Static priorities are given based on the Deadline Monotonic scheduling [11], which is the most optimal between the ﬁxed priority algorithms [13].

Task name

Task type

Period / Minimum inter-arrival time (ms)

Deadline (ms)

Priority

Regular_Producer On_Call_Producer Activation_Log_Reader External_Event_Server

Cyclic Sporadic Sporadic Interrupt sporadic

1000 3000 3000 5000

500 800 1000 100

7 5 3 11

Table 1: Attributes of the tasks in the application [1]

Ada protected objects [RM 9.4] are used to ensure mutually exclusive access to shared resources, whereas protected entries are used only for task synchronization purposes where data exchange is involved.

3 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

Figure 2: Architecture of the example application [1].

In a real-time application, each protected object has a priority ceiling which represents the maximum priority of any task that calls the object. The Ada Real-Time Systems Annex supports the deﬁnition of Locking_Policy [RM D.3] and implements the resource locking protocol called Immediate Priority Ceiling Protocol (IPCP) [5], which is similar to the Priority Ceiling Protocol (PCP).

PCP is an improvement of the Priority Inheritance Protocols (PIP) which allow a task to execute with an enhanced priority if it is blocking (or could block) a higher-priority task. In addition to PIP, PCP prevents deadlock and reduces blocking to its minimum value: every job is blocked at most once for the duration of a critical section, no matter how many jobs conﬂict with it [14].

The IPCP is similar to PCP in its use of the ceiling priority, but it has a different set of rules on how a task behaves under the ceiling locking protocol.

1. A task may lock a protected object if it is not yet locked.

2. When it enters a critical section it immediately inherits the priority ceiling of the protected object, and recovers its entry priority when it exits the section.

This protocol effectively prevents any task from starting to execute until all the shared resources it needs are free. This means that no separate mutual exclusion mechanism, such as semaphores, is needed to lock shared resources. It is also cheap to implement at run time and incurs in less context switches. By raising priorities as soon as a resource is locked, whether a higher priority task is trying to access it or not, the protocol avoids the need to make complex scheduling decisions while tasks are already executing.

Protected object names

User tasks

Ceiling priority

Request_Buffer Event_Queue Activation_Log

Regular_Producer (Deposit), On_Call_Producer (Extract) External interrupt (Signal), External_Event_Server (Wait) External_Event_Server (Write), Activation_Log_Reader (Read)

9 System.Interrupt_Priority’First 13

Table 2: Attributes of the protected objects in the application [1]

4 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

1.3 Ada tasks for real-time systems

In the Ada Ravenscar, a periodic task has an inﬁnite loop within which there is a self-suspension statement that ensures that the task executes regularly [32]:

with Ada.Real_Time; ...

task Periodic_Task;

use Ada.Real_Time;

task body Periodic_Task is Period : Time_Span := Milliseconds (1000);

-- define the period of the task , 1000 ms Next : Time; begin Next := Clock;

in

this

example

-- start time loop

-- undertake the work of the task Next := Next + Period; delay until Next; end loop; end Periodic_Task;

However, we should bear in mind that Period is the minimum length of time between the release times of instances of the task. The subsequent jobs will be released periodically only if the loop always completes within Period time units. If the response time of an instance of the thread exceeds the value, the next instance is released only as soon as the current instance completes. Therefore there will be both a deadline miss of the current job and a delay in activation of the subsequent instance.

A sporadic task requires instead a protected object to control its release:

task Sporadic_Task; protected Sporadic_Controller

entry Wait_Next_Invocation ;

procedure Release_Sporadic ; private

Barrier : Boolean := False; end Sporadic_Controller ;

is

task body Sporadic_Task is begin loop Sporadic_Controller . Wait_Next_Invocation ; -- undertake the work of the task end loop; end Sporadic_Task;

protected body Sporadic_Controller is

entry Wait_Next_Invocation when Barrier is begin Barrier := False; end;

procedure Release_Sporadic begin Barrier := True; end; end Sporadic_Controller ;

is

The task body for an event-triggered task that conforms to the Ravenscar Proﬁle typically has, as its last statement, an outermost inﬁnite loop whose ﬁrst statement is either a call to a protected entry or a call to a Suspension Object [1]. The Suspension Object is used when no other effect is required in the signalling operation; for example, no data is to be transferred from signaller to waiter. In contrast, the protected entry is used for more elaborate event signalling, when additional operations must accompany the resumption of the event-triggered task.

5 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

1.4 Software interrupts

As mentioned above, the system may receive interrupt requests (IR) from an external manual push-button. Such IR is handled by the NVIC Interrupt Controller, which is a part of the Cortex-M processor that handles the exceptions and the interrupt conﬁgurations, prioritization and masking [2].

To automate the arrival of interrupts throughout our following analysis, we periodically trigger an IR via software by using a Software Trigger Interrupt Register (STIR). We ﬁrst deﬁne a system package ST.EXTI where we gain access to the STM32F4 Interrupts and Events registers. Then, setting a pending bit to the appropriate interrupt line in the STIR triggers the IR for the external push-button.

Lastly, the whole process is executed within a new periodic task Force_Interrupt, whose loop body simulates the worst-case sporadic behaviour of the interrupt. The worst-case happens when the subsequent interrupts arrive at the minimum interarrival time, used as period of the task.

with with with with

Ada.Real_Time; Ada.Text_IO; ST; use ST; ST.EXTI; use ST.EXTI;

use Ada.Real_Time;

package body Force_Interrupt is

Period : constant Ada.Real_Time.Time_Span := Ada.Real_Time.Milliseconds (5000); Button_Line : constant Interrupt_Line := 0; -- The User Button is connected to EXTI0 (aka Line 0)

task body Force_Interrupt is -- for periodic suspension Next_Time : Ada.Real_Time.Time; begin loop Next_Time := Next_Time + Period;

EXTI. Software_Trigger_Interrupt_Register .Line := (Button_Line => True , others => False ); Ada.Text_IO.Put_Line (" Interrupt␣generated" );

delay until Next_Time; -end loop; end Force_Interrupt ; end Force_Interrupt ;

delay

statement at end

of

loop

The overhead introduced by the newly deﬁned task is negligible and thus will not be considered during the different analysis of the paper.

2

System model and notation

The described application is a set of tasks executing in the same processor, grouped into entities called transactions [37]. Each transaction Γ i is activated by a periodic sequence of external events with period T i , and contains a set of tasks. Each task is released when a relative time offset elapses after the arrival of the external event. Each activation of a task releases the execution of one instance of that task, called a job.

Figure 3 shows an example of such system: the horizontal axis represents time; down-pointing arrows represent the arrival of the external events associated to each transaction, while up-pointing arrows represent the activation times of each task; and shaded boxes represent task execution [36]. Each task has its own unique priority and in this example the task set is scheduled using a preemptive FPS.

Each task will be identiﬁed with two subscripts: the ﬁrst one identiﬁes the transaction to which it belongs, and the second one the position that the task occupies within the tasks of its transaction, when they are ordered by increasing offsets. In this way, τ ij will be the j-th task of transaction Γ i , with an offset of Φ ij and a worst-case execution time of C ij . In addition, we will allow each task to have jitter, that is to have its activation time delayed by an arbitrary amount of time between 0 and the maximum jitter for that task, which we will call J ij . This means that the activation time of task τ ij may occur at any time between t 0 + Φ ij and t 0 + Φ ij + J ij , where t 0 is the instant at which the external event arrived.

6 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

Figure 3: Timeline of a system composed of transactions with offsets [36]

The reason for this is that tasks must execute in order, i.e. On_Call_Producer can start executing only after the preceding task in the transaction, Regular_Producer, has completed. The precedence constraints are modeled by assigning each task an initial offset and a maximum jitter [37]. The initial offset Φ ij of a periodic task is the instant of the ﬁrst activation of the task. However, a task belonging to a transaction may start only after it has been activated and the preceding task in the transaction has completed execution. Hence maximum jitter is the maximum time interval it can occur from the task activation until the completion time of the preceding task in the transaction.

In addition to maximum jitter, tasks offsets are allowed to vary dynamically, from one activation to the next, within a minimum and a maximum value: Φ ij ∈ [Φ ij min , Φ ij max ]. Dynamic offsets are useful in systems in which tasks suspend themselves, like in the case of protected object entries. The task On_Call_Producer τ i2 calls the protected entry Extract and suspends itself until the task Regular_Producer τ i1 replenishes the Request_Buffer. The activation time of On_Call_Producer depends on the completion time of the Regular_Producer and thus the offset for task τ i2 is variable in the interval Φ i2 ∈ [R i1 min , R i1 max ], where R i1 min and R i1 max are respectively the best-case and worst-case response times of task Regular_Producer.

For each task τ ij we deﬁne its response time as the difference between its completion time and the instant at which the associated external event arrived. The worst-case response time will be called R ij . Each task has also an associated global deadline, D ij , which is again relative to the arrival of the external event.

If tasks synchronize using shared resources in a mutually exclusive way, they will be using the aforementioned Immediate Priority Ceiling Protocol. The effects of lower priority tasks on a task under analysis τ ab are bounded by an amount called the blocking term B ab , calculated as the maximum of all the critical sections of lower priority tasks that have a priority ceiling higher than or equal to the priority of τ ab .

2.1 Offset-based analysis

Rate monotonic analysis (RMA) [11] allows an exact calculation of the worst-case response time of tasks in singleprocessor real time systems, including the effects of task synchronization, the presence of aperiodic tasks, the effects of deadlines before, at or after the periods of the tasks, tasks with varying priorities, overhead analysis, etc. However, classic RMA [29] cannot provide exact solutions in systems in which tasks suspend themselves. Classic techniques for these systems are based on the assumption that all tasks are independent, and thus they lead to pessimistic results [36].

For building the worst-case scenario for a task τ ab under analysis, the analysis must consider the critical instant that leads to the worst-case busy period. A task τ ab busy period is an interval of time during which the CPU is busy processing task τ ab or higher priority tasks. For tasks with offsets, it must take into account that the critical instant may not include the simultaneous activation of all higher priority tasks, as it was the case when all tasks were independent. The existence of offsets makes it impossible for some sets of tasks to simultaneously become active.

7 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

Works on such problem has been the base of offset-based analysis, ﬁrst proposed by Tindell and Clark [37] and later improved by Palencia and Gonzàlez [36] who called it Worst-Case Analysis of Dynamic Offsets. In such analysis, the best and worst-case response times of each task are used to set the offset and the jitter of the successive task in the same transaction.

3

Execution times

To use the described model, upper bounds on the execution times are needed. Unfortunately precise Worst-Case Execution Time (WCET) is hard to ﬁnd due to pipelines, caches and other performance enhancing techniques used on contemporary computer architectures [38]. This effects are reduced in the case of a more predictable bare-board environment, which can nevertheless suffers a small amount of indeterminism. Therefore pessimistic scheduling is needed in order to provide an ofﬂine guarantee that all hard deadlines will be met, but leads to poor processor utilization.

Figure 4: The lower curve represents a subset of measured executions. The darker curve, an envelope of the former, represents the times of all executions. [38].

Figure 4 shows the set of all execution times as the upper curve. Its minimum and maximum are the best- and worst-case execution times, respectively, abbreviated BCET and WCET. In most cases, the space is too large to exhaustively explore all possible executions and thereby determine the exact worst- and best-case execution times.

The common method to estimate execution time bounds is to measure the end-to-end execution time of the task for a subset of the possible executions. This determines the minimal observed and maximal observed execution times. These will, in general, overestimate the BCET and underestimate the WCET.

Nevertheless, we have adopted the same approach, aware of the mentioned perils. In most cases, we had deterministic execution times with always the same exact number of CPU cycles or with a difference less than 1µs, except for the Whetstone operations which showed more signiﬁcant variation. However, we always had very low standard errors minor than 1%. The example application is quite simple, comprised of few tasks with predictable executions and the only interrupts are the periodic ticker and the external push button.

Execution times are measured using two custom packages: System_Overhead and Task_Metrics. The former is able to provide the exact number of elapsed CPU ticks, which is then converted as seconds by dividing it with the clock frequency. It’s used to measure runtime overhead, whereas the latter provides task execution time if self-suspension can happen, which would make usage of the clock ticks unsuitable.

-- system -overhead.ads with System.BB.Time; use with System.Semihosting; package System_Overhead is pragma Preelaborate; procedure Start_Tracking ;

System.BB.Time;

-- Avoid counting sub -program procedure Start_Sub_Program ;

execution

time

8 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

procedure

procedure

End_Sub_Program ;

End_Tracking (Item :

procedure Log_Time; -- Just log the current end System_Overhead ;

clock

String := " " );

time

with with

System.BB.Time; use System.Semihosting;

System.BB.Time;

-- system -overhead.adb package body System_Overhead is Initial_Value : Time := 0; Start_Sub_Value : Time := 0; End_Sub_Value : Time := 0;

procedure Start_Tracking is begin

Initial_Value := Clock;

Start_Sub_Value := 0;

End_Sub_Value := 0; end Start_Tracking ;

procedure Start_Sub_Program begin Start_Sub_Value := Clock; end Start_Sub_Program ;

procedure End_Sub_Program is begin End_Sub_Value := Clock; end End_Sub_Program ;

is

procedure End_Tracking (Item : String := " " ) Now : constant Time := Clock; Sub_Program : Time; Elapsed : Time; begin -- Sometime End_Tracking may be called before Start_Tracking if Initial_Value = 0 then return; end if;

is

Sub_Program := End_Sub_Value - Start_Sub_Value ; Elapsed := Now - Initial_Value - Sub_Program;

Put_Line (Item & Time ’Image (Elapsed )); end End_Tracking;

procedure Log_Time is begin Put_Line (Time ’Image (Clock )); end Log_Time;

procedure Put_Line (Item : String) is begin System.Semihosting.Put (Item & ASCII.CR & end Put_Line; end System_Overhead ;

ASCII.LF);

The System_Overhead package uses the board-speciﬁc System.BB.Time package, which provides the Clock function to read the real-time monotonic clock. It’s the same primitive used under-the-hood by Ada.Real_Time [RM D.8] to provide physical time as observed in the external environment.

9 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

The package Task_Metrics has the same interface as System_Overhead, but it replaces System.BB.Time with Ada.Execution_Time [RM D.14] to measure the elapsed execution time of a task. The ravenscar-full-stm32f429disco runtime supports the Ada 2012 implementation to separately account for the execution time of interrupt handlers [35].

The functionality of the real-time clock (RTC) and execution time clocks (ETCs) are quite similar: both clocks support high accuracy measurement of the monotonic passing of time since an epoch, and both support calling a protected handler when a given timeout time is reached. The main difference is that the RTC is always active, while an ETC is active only when its corresponding task or interrupt is executed.

3.1 Semi-hosting

It is worth mentioning the usage of semi-hosting [21], which allows print messages to be transferred from the board to the host computer using the debug connection. Using semi-hosting for printing is usually much slower than UART because the semi-hosting mechanism needs to halt the processor, but on the other hand the system tick timer Sys_Tick counter is stopped during the transmission, thus avoiding affecting the schedule of the tasks. The example application has no timing requirements relative to external interrupts, with the exception of the manual push-button.

Both System_Overhead and Task_Metrics use semi-hosting to send execution time data to the host computer. Besides, it is leveraged also in the ravenscar-full-stm32f429disco runtime implementation of the Ada.Text_IO package, whose method Put_Line is called by the tasks.

The runtime deﬁnes a semi-hosting buffer size of 128 characters before ﬂushing a string, therefore we have padded all the print messages with white space to reach the ﬁxed size of 50 characters. By doing so we have ﬁxed execution time due to buffer insertion, simplifying MAST modeling of the Put_Line operation.

4

Deadline miss detection

In later analysis, we will want to achieve the maximum schedulable utilization by analyzing a MAST model with low utilization and then increasing tasks utilization until the system no longer meets its deadlines. However, for design attributes to turn into system properties, we must enforce them at runtime. In particular, we have to check that the jobs of the tasks always complete before their respective deadline, to ensure consistency between the MAST analysis and the execution [34].

Fortunately, Ada 2005 introduced a lower level facility that maps a handler to a speciﬁc time without the need to use a separate task. The handler is associated with a timing event. When the event time is due, and detected by the runtime, the handler code is executed.

The most effective way for an implementation to support timing events is to execute the handlers directly from the interrupt handler of the clock [33], and this is indeed what happens in ravenscar-full-stm32f429disco.

-- deadline_miss.ads with System; with Ada.Real_Time; use Ada.Real_Time; with Ada.Real_Time.Timing_Events; use Ada.Real_Time. Timing_Events ;

package type

Deadline_Miss is Deadline_Handler

is

limited

private;

procedure Set_Deadline_Handler ( H: in out Deadline_Handler ; Name : String; At_Time : in Time ); procedure Cancel_Deadline_Handler (H: in out

Deadline_Handler );

private

protected type Deadline_Handler with Priority => System.Interrupt_Priority ’Last is procedure Notify_Deadline_Miss (Event : in out

Timing_Event );

procedure

Set_Deadline_Handler (Name : String; At_Time : in Time );

10 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

procedure

Cancel_Deadline_Handler ;

private Tag : String (1..3) := " N/A" ; Event : Timing_Event;

end Deadline_Handler ; end Deadline_Miss;

-- deadline_miss.adb with Ada.Real_Time; use Ada.Real_Time; with Ada.Text_IO; use Ada.Text_IO;

package body Deadline_Miss is

protected body Deadline_Handler is procedure Notify_Deadline_Miss (Event : in out Timing_Event ) is begin --raise Program_Error with " Detected deadline miss " ; Ada.Text_IO.Put_Line (" Deadline␣Miss␣Detected␣-␣" & Tag ); end Notify_Deadline_Miss ;

procedure Set_Deadline_Handler (Name : String; At_Time : in Time) is begin Tag := Name;

Set_Handler (Event , At_Time , Notify_Deadline_Miss ’Access ); end Set_Deadline_Handler ;

procedure Cancel_Deadline_Handler is Cancelled : Boolean; pragma Unreferenced (Cancelled ); begin Cancel_Handler (Event , Cancelled ); end Cancel_Deadline_Handler ; end Deadline_Handler ;

procedure Set_Deadline_Handler ( H: in out Deadline_Handler ; Name : String; At_Time : in Time) is begin H. Set_Deadline_Handler (Name , At_Time ); end Set_Deadline_Handler ;

procedure Cancel_Deadline_Handler (H : in begin H. Cancel_Deadline_Handler ; end Cancel_Deadline_Handler ; end Deadline_Miss;

out Deadline_Handler ) is

The measured execution times include overrun detection overhead for Regular Producer, On Call Producer and Activation Log Reader.

5

MAST

MAST [4] is a Modeling and Analysis Suite for Real-Time Applications and its main goal is to provide an open source set of tools that enables engineers developing real-time applications to check the timing behavior of their application, including schedulability analysis with hard timing requirements.

It is designed to handle both ﬁxed priority and dynamic priority scheduled systems, although offset-based analysis for Earliest Deadline First scheduling is still missing as of the time of writing. However, within ﬁxed priorities, different scheduling strategies are allowed, including preemptive and non preemptive scheduling, interrupt service routines, sporadic server scheduling, and periodic polling servers.

11 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

The MAST model is designed to handle both single-processor as well as multiprocessor or distributed systems. In both cases, emphasis is placed on describing event-driven systems in which each task may conditionally generate multiple events at its completion. A task may be activated by a conditional combination of one or more events. The external events arriving at the system can be of different kinds: periodic, unbounded aperiodic, sporadic, bursty, or singular (arriving only once).

The system model facilitates the independent description of overhead parameters such as processor overheads (including the overheads of the timing services). This frees us from the need to include all these overheads in the actual application model, thus simplifying it and eliminating a lot of redundancy.

MAST provides also a graphical editor to generate the system using the MAST ASCII description, but it’s still immature to be reliable and the presence of several graphical bugs causes an annoying experience. A graphical display of results is also available.

5.1 The MAST Model

We now proceed to describe the MAST model of the example application. In this phase, it will represent a FPS set of independent tasks, further sections will provide the needed changes to match a chain of dependant tasks or to support EDF scheduling. For a full reference to the MAST syntax, visit "Description of the MAST Model" [6].

5.1.1 Processing Resources

Processing Resources represent resources that are capable of executing abstract activities, including conventional CPU processors. Among its attributes we have the range of priorities valid for normal operations on that processing resource, and the speed factor. We have left the default value as speed factor, meaning that execution times will be expressed as seconds.

Normally when dealing with hard real-time analysis, we would also deﬁne only the Worst-Case Execution Time (WCET) of the operations but, since we have dynamic offsets depending on them, we include both best and worst execution times because we don’t know for sure that always having the WCET corresponds to worst system performance. We may for instance have anomalies as in the case of multiple processors [17].

Processing_Resource (

Type => Regular_Processor , Name => cpu , Max_Interrupt_Priority => 255, Min_Interrupt_Priority => 241, Worst_ISR_Switch => 2.578E-06, System_Timer =>

( Type => Ticker ,

Worst_Overhead => 3.844E-06,

Period => 0.001000) , Speed_Factor => 1.00);

The board is built with only one CPU, whereas the interrupt ranges are taken from the System package in the ravenscar-full-stm32f429disco runtime. Task priorities span from 1 to 240, while interrupt priorities go from 241 to 255. Thus it’s possible to have at max 240 distinct task priorities, if more priorities are needed one can use the technique described in [15].

The Interrupt Service Routine (ISR) overhead is measured as the time taken to run the Interrupt_Handler in System.BB.Board_Support package, without counting the execution time of the application interrupt handler. In Ada, the code in the handler itself executes at the hardware interrupt level, whereas the major part of the processing of the response to the interrupt is moved into an event response task, which executes at a software priority level with interrupts fully enabled.

The ﬁrst procedure executes for a very short time-typically executing only the instructions that are strictly necessary to service the interrupt and reset the associated piece of hardware. The second one is implemented as a task that is activated from the interrupt handler and its priority is assigned as deﬁned in Table 1.

Both parts are not accounted into the ISR overhead. However, the overhead takes into account the management of the aforementioned Execution Time Clocks (ETC) [35].

12 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

The system timer used by the board is Tick Scheduling [16], which represents a system that has a periodic clock interrupt that arrives at the system. When this interrupt arrives, all timed events whose expiration time has already passed, are activated.

Tick scheduling introduces two additional factors that must be accounted for in schedulability analysis. First, the fact that a job is ready may not be noticed and acted upon by the scheduler until the next clock interrupt. This introduces additional jitter that may delay the completion of the job.

Second, a self-suspended task is held in a queue which we will call the delay queue. When the scheduler executes, it scans the delay queue and moves the jobs that have been released since the last clock interrupt to the ready job queue and places them there in order of their priorities. Once in the ready queue, the jobs execute in priority order without intervention by the scheduler. The time the scheduler takes to scan and move the jobs introduces additional scheduling overhead. Similar overhead must be accounted for any timing events that need to be triggered.

The scheduling overhead is accounted in the analysis using the technique described in [30]. MAST can model the scheduler as a periodic task τ 0 whose period is p 0 . This task has the highest priority among all tasks in the system. Its execution time C 0 is the amount of time the scheduler takes to service the clock interrupt. This time is spent even when there is no job in the pending job queue.

In the ravenscar-full-stm32f429disco runtime, the period p 0 of the tick is 1ms, deﬁned in the System.BB.Board_Support package, and the worst overhead is measured as the time taken to execute Timer_Interrupt_Handler, the trap handler deﬁned in the same package for the Sys_Tick trap.

5.1.2 Schedulers

Schedulers represent the runtime procedures that implement the appropriate scheduling strategies to manage the amount of CPU processing capacity. They can have a hierarchical structure to model hierarchical scheduling [18], but the example application has only one primary scheduler with ﬁxed priority policy.

Figure 5: Fixed Priority Scheduler which manages the CPU

Scheduler (

Type => Primary_Scheduler , Name => fps , Host => cpu , Policy =>

( Type => Fixed_Priority ,

Worst_Context_Switch => 3.090E-06,

Max_Priority => 240,

Min_Priority => 1));

The context switch overhead is measured as time to set the context switch interrupt Pend_SV as pending and the execution time of Pend_SV_Handler in the System.BB.CPU_Primitives.Context_Switch_Trigger package, which saves the registers of active context and restores the ones of the new context. One some platforms, like in the case of the STM32F429I-Discovery board equipped with an ARM Cortex-M4 core, the context switch requires the triggering of a trap [22]. Then context switching is usually carried out in the Pend_SV trap handler.

13 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

5.1.3 Scheduling Servers

Scheduling Servers represent schedulable entities in a processing resource, in particular if the resource is a processor, the scheduling server is a task or thread of control. As a matter of fact, each of them has a priority and a type, which for our application may be Fixed_Regular_Policy or Interrupt_FP_Policy. The former represents a regular preemptive ﬁxed priority, whereas the latter models an interrupt service routine. In reality, we have not used a Interrupt_FP_Policy as the interrupt overhead is negligible.

Figure 6: Scheduling Servers representing the application tasks

Scheduling_Server (

Type => Regular , Name => regular_producer , Server_Sched_Parameters =>

( Type => Fixed_Priority_Policy ,

The_Priority => 7,

Preassigned => YES), Scheduler => fps);

Scheduling_Server (

Type => Regular , Name => on_call_producer , Server_Sched_Parameters =>

( Type => Fixed_Priority_Policy ,

The_Priority => 5,

Preassigned => YES), Scheduler => fps);

Scheduling_Server (

Type => Regular , Name => activation_log_reader , Server_Sched_Parameters =>

( Type => Fixed_Priority_Policy ,

The_Priority => 3,

Preassigned => YES), Scheduler => fps);

Scheduling_Server (

Type => Regular , Name => external_event_server , Server_Sched_Parameters =>

( Type => Fixed_Priority_Policy ,

The_Priority => 11,

Preassigned => YES), Scheduler => fps);

5.1.4 Shared Resources

Shared Resources represent resources that are shared among different tasks, and that must be used in a mutually exclusive way. Therefore, protected objects are modeled as Shared Resourses that use the Immediate Priority Ceiling Protocol described above.

Shared_Resource

(

14 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

Figure 7: Shared Resources of the application

Type => Immediate_Ceiling_Resource , Name => request_buffer , Ceiling => 9, Preassigned => YES);

Shared_Resource (

Type => Immediate_Ceiling_Resource , Name => activation_log , Ceiling => 13, Preassigned => YES);

Shared_Resource (

Type => Immediate_Ceiling_Resource , Name => event_queue , Ceiling => 241, Preassigned => YES);

5.1.5 Operations

MAST Operations represent a piece of code to be executed by the processor. We have used the following classes of operations:

• Simple: it represents a simple piece of code or a message. It may have the list of shared resources to lock before executing the operation, and the list of shared resources that must be unlocked after executing the operation. Simple Operations have been used to model methods of protected objects. The execution time is measured from the ﬁrst line of the method to the last one, thus it doesn’t include the runtime overhead associated with invoking protected methods.

• Composite: it represents an operation composed of an ordered sequence of other operations, simple or composite. The execution time attribute of this class cannot be set, because it is the sum of the execution times of the comprised operations.

• Enclosing: it represents an operation that contains other operations as part of its execution, but in this case the total execution time must be set explicitly; it is not the sum of execution times of the comprised operations, because other pieces of code may be executed in addition. For each protected method there is an Enclosing Operation which takes into account the overhead associated with calling protected methods. Sometimes it corresponds to a method deﬁned by the application, other times it’s deﬁned in the model speciﬁcally to include the runtime overhead. By doing so, we can deﬁne the caller procedures as simple Composite operations.

Examples of protected methods as Simple Operations:

Operation

(

Type Name Worst_Case_Execution_Time Shared_Resources_To_Lock

( request_buffer), Shared_Resources_To_Unlock

( request_buffer ));

=> Simple , => rb_deposit , => 2.000E-06, =>

=>

Operation

(

Type Name Worst_Case_Execution_Time Shared_Resources_To_Lock

=> Simple , => rb_extract , => 2.000E-06, =>

15 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

( request_buffer), Shared_Resources_To_Unlock ( request_buffer ));

=>

Examples of Enclosing Operations including protected methods overhead:

Operation (

Type => Name => Worst_Case_Execution_Time => Composite_Operation_List => ( rb_deposit ));

Enclosing , ocp_start , 6.000E-06,

Operation (

Type => Name => Worst_Case_Execution_Time => Composite_Operation_List => ( rb_extract ));

Enclosing , rb_extract_enclosing , 7.000E-06,

Complete example of the MAST representation of a job of the task Regular_Producer:

Operation

(

Type Name Worst_Case_Execution_Time

=> Simple , => rp_small_whetstone , => 0.019363);

Operation

(

Type Name Worst_Case_Execution_Time

=> Simple , => due_activation , => 1.000E -06);

Operation (

Type => Name => Worst_Case_Execution_Time => Composite_Operation_List => ( rb_deposit ));

Enclosing , ocp_start , 6.000E-06,

Operation

(

Type Name Worst_Case_Execution_Time

=> Simple , => check_due , => 1.000E -06);

Operation

(

Type Name Worst_Case_Execution_Time

=> Simple , => alr_signal , => 5.000E -06);

Operation

(

Type Name Worst_Case_Execution_Time

=> Simple , => put_line , => 1.400E -05);

Operation (

Type => Name => Composite_Operation_List => ( rp_small_whetstone , due_activation , ocp_start , check_due , alr_signal , put_line ));

Composite , rp_operation ,

16 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

Operation (

Type => Name => Composite_Operation_List =>

( overrun_detection ,

Composite , regular_producer ,

rp_operation ,

delay_until ));

The Small_Whetstone algorithm allows to control the computational workload of Regular_Producer, On_Call_Producer and Activation_Log_Reader. By changing the workload parameters of Small_Whetstone in the application, we will be able to test different utilisation of the system with likewise ease in updating the MAST model.

The Whetstone execution time is proportional to the workload parameter and exhibits deterministic behaviour. If we wanted to try what would happen by increasing the load of factor 10, we would just multiply the WCET in the model by 11, without the need to measure again all the Enclosing operations, since all the methods which use Whetstone are deﬁned as Composite. However we have been careful to avoid forgetting to include any overhead in a Enclosing method and we have made sure they are not impacted by any change of the Whetstone workload.

5.1.6 Transactions

A Transaction represents a transaction of our model (see Section 2) as a graph of event handlers and events, and form interrelated activities executed in the system. A Transaction is deﬁned with three different components: a list of External Events, a list of Internal Events (with their timing requirements if any), and a list of Event Handlers.

Events may be internal or external, and represent channels of event streams, through which individual event instances may be generated.

Internal Events are generated by an Event Handler. Internal Events have timing requirements, a Global Deadline relative to the arrival of a Referenced External Event. The MAST language allows also to use Local Deadlines, relative to the arrival of the event that activated that Event Handler. All of our deadlines are Hard Deadlines, e.g. they must be met in all cases, including the worst case.

External events model the interactions of the system with external components or devices through interrupts, signals, etc., or with hardware timing devices. They have a double role in the model: on the one hand they establish the rates or arrival patterns of activities in the system. On the other hand, they provide references for deﬁning global timing requirements. MAST supports different arrival patterns, of which we used the following: Periodic represents a stream of events that are generated periodically, such as from the Tick Scheduling; Sporadic as a stream of aperiodic events that have a minimum interarrival time.

Figure 8: Event Handlers

Event Handlers in ﬁgure 8 represent actions that are activated by the arrival of one event, and that in turn generate one or more events at their output. There are two fundamental classes of Event Handlers. The Activities represent the execution of an operation by a Scheduling Server (a task), in a processing resource (the CPU). The other kinds of Event Handlers are just a mechanism for handling events, with no runtime effects. In the model we have used the following classes:

• Activity: an instance of an operation, to be executed by a Scheduling Server;

• System Timed Activity: an activity that is activated by the system timer, and thus is subject to the aforementioned jitter associated with it;

17 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

• Multicast: it is an event handler that generates one event in every one of its outputs each time an input event arrives;

• Rate Divisor: it is an event handler that generates one output event when a number of input events equal to the Rate Factor have arrived;

• Offset: an event handler that generates its output event after a time interval has elapsed from the arrival of some (previous) external event. If the time interval has already passed when the input event arrives, the output event is generated immediately.

We now proceed to model the three transactions which model the respective independent tasks. We will start with an initial analysis of the system as stand-alone tasks, then compare its maximum utilisation with the model using dynamic offsets to represent dependant tasks.

Figure 9: Regular_Producer transaction

Transaction (

Type => regular , Name => rp_transaction , External_Events => ( ( Type => Periodic , Name => e1 , Period => 1.000 , Max_Jitter => 0.000 , Phase => 0.000)) , Internal_Events => ( ( Type => Regular , Name => rpo1 , Timing_Requirements => ( Type => Hard_Global_Deadline , Deadline => 0.500000 , Referenced_Event => e1))), Event_Handlers => ( (Type => System_Timed_Activity , Input_Event => e1 , Output_Event => rpo1 , Activity_Operation => regular_producer , Activity_Server => regular_producer )));

The main event stream is modeled as a transaction activated by the periodic system timer, with period of 1s. The event is handled by the regular_producer operation, representing a job of the same name. The Event Handler is of type System_Timed_Activity to take into account the jitter caused by the tick scheduling.

Figure 10: On_Call_Producer transaction

Transaction (

Type Name External_Events

( ( Type

=> regular , => ocp_transaction , =>

Name

=> Sporadic , => ocp_activation ,

18 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

Figure 11: Activation_Log_Reader transaction

Avg_Interarrival Distribution Min_Interarrival Internal_Events => ( ( Type => Regular , Name => ocpo1 , Timing_Requirements => ( Type => Hard_Global_Deadline , Deadline => 0.800000 , Referenced_Event => ocp_activation ))), Event_Handlers => ( (Type => Activity , Input_Event => ocp_activation , Output_Event => ocpo1 , Activity_Operation => on_call_producer , Activity_Server => on_call_producer )));

=> 0.000 , => UNIFORM , => 3.000)) ,

The sporadic On_Call_Producer event stream is modeled as activated by a bounded aperiodic event, with minimum interarrival time of 3s and uniform distribution. Similar modelling has been done for the Activation_Log_Reader sporadic task.

Figure 12: External push-button transaction

Transaction (

Type Name External_Events ( ( Type Name Avg_Interarrival Distribution Min_Interarrival Internal_Events => ( ( Type => Regular , Name => eqo1 , Timing_Requirements => ( Type => Hard_Global_Deadline , Deadline => 0.100000 , Referenced_Event => button_click ))), Event_Handlers => ( (Type => Activity , Input_Event => button_click , Output_Event => eqo1 , Activity_Operation => external_event_server , Activity_Server => external_event_server )));

=> regular , => interrupt_transaction , =>

=> Sporadic , => button_click , => 0.000 , => UNIFORM , => 5.000)) ,

19 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

The push-button interrupt event stream is modeled as triggered by a sporadic event of 5s as minimum interarrival time and it’s handled by the external_event_server job at software priority. The interrupt handler at hardware interrupt priority has not been modeled since it’s execution time is negligible.

5.2 MAST analysis

As of the time of writing, MAST is at version 1.5.1 and supports the analysis tools [7] in Figure 13. The techniques relevant for this paper are:

Figure 13: MAST analysis tools [7].

• Classic RM Analysis: it implements the classic exact response time analysis for single-processor ﬁxed-priority systems and corresponds to the Technique "Calculating response time with arbitrary deadlines and blocking" in [26]. Although it’s called Rate Monotonic, it bases on the ﬁnal work by Tindell regarding Deadline Monotonic analysis to include jitters [23];

• Holistic Analysis: this analysis extends the response time analysis to multiprocessor and distributed systems. It is not an exact analysis, because it makes the assumption that tasks of the same transaction are independent. It was ﬁrst developed for ﬁxed priority systems by Tindell and Clark [24]. It has no use for our purposes, but it is worth mentioning to the reader because it can support both FPS and EDF monoprocessor and has less restrictions compared to Classic RM Analysis, as explained below. In terms of our example application, both techniques provides equivalent results;

• EDF Monoprocessor / Single Processor: it implements the exact response time analysis for single-processor EDF systems ﬁrst developed by Spuri [39];

• Offset Based Approximate Analysis: this is a response time analysis for multiprocessor and distributed systems that improves the pessimism of the holistic analysis by taking into account that tasks of the same transaction are not independent, through the use of offsets. Offset based analysis for ﬁxed priorities was ﬁrst introduced by Tindell [37] and then extended to distributed systems by Palencia and González [36];

• Offset Based Approximate with Precedence Relations Analysis: this is an enhancement of the offset based approximate analysis for ﬁxed priority systems in which the priorities of the tasks of a given transaction are used together with the precedence relations among those tasks to provide a tighter estimation of the response times;

• Offset Based Slanted Analysis: this is another enhancement of the offset based approximate analysis for ﬁxed priority systems in which the maximum interference function is deﬁned with a tighter approximation. This

20 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

method provides better results that the Offset-Based Approximate Analysis, but it is uncertain if it gets better results than the method with precedence relations.

In addition, the analysis tools are subject to different restrictions [8]. The most signiﬁcant ones are:

• No_Hard_Local_Deadlines: Hard Local Deadlines cannot be used as Timing Requirements;

• Referenced_Events_Are_External_Only: no internal events can be referenced by Global Deadlines;

• Simple_Transactions_Only: checks that every transaction has only a continuous sequence of activities executed by the same server. This restriction is required by the Rate Monotonic analysis and the EDF Monoprocessor analysis;

• Linear_Plus_Transactions_Only: less restrictive than Simple_Transactions_Only, checks that every transaction only has one external event and is not multipath, e.g. it has no Multicasts. This restriction is required by the Holistic Analysis and the different Offset based analysis tools;

• Restricted_Multipath_Transactions_Only: checks that every transaction has a single input event, has no branch elements (Delivery or Query Servers), and has no Rate Divisors. It also checks that the transaction follows the set of allowed constructs mentioned in [8]. This restriction is required by the Holistic analysis.

As ﬁnal note, as of the time of writing, offset-based analysis with EDF tasks fallbacks to holistic analysis [7], which in turn does not support shared resources in EDF yet.

6

FPS analysis

We start the analysis with ﬁxed priority scheduling (FPS) and a MAST model which represents the tasks as stand-alone. Later, we will try to more strictly model the formal transactions comprised of dependent tasks.

To check that the system meets the deadlines, it sufﬁces to run it for at least the ﬁrst hyperperiod amount of time. Assuming sporadic tasks as periodic with period equal to the minimum interarrival time, which is the worst case, the hyperperiod is LCM(1, 3, 5) = 15s. The hyperperiod of a set of tasks is least common multiple of all periods.

6.1 Independent tasks

We start with the Rate Monotonic analysis of the initial system.

Optimum Resource request_buffer => activation_log => event_queue => 241

Ceilings:

7 11

A ﬁrst analysis suggests that smaller values can be used as ceilings for the protected objects Request_Buffer and Activation_Log. This possible improvement is expected since the two values are the highest priorities of the tasks Regular_Producer and External_Event_Server respectively. We leave the ceilings intact nevertheless, since the ceiling is a required to be an upper bound of the priorities between the tasks the request the resource, not the least upper bound. Having some spare priorities between the task priorities and the ceilings might prove to be useful if we need to separate a task into two distinct tasks with proper offset to better model the application [37].

Task

WCET

regular_producer on_call_producer activation_log_reader

0.019333

0.007126

0.003582

Transaction

R max

Slack

Worst blocking time

Jitter

rp_transaction ocp_transaction alr_transaction interrupt_transaction

0.020434 2470.0%

0.026592 10776.6%

0.030195 26600.8%

2.102E-05 >=100000.0%

2.000E-06

1.000E-06

0.00

1.000E-06

0.001101

0.019472

0.026613

1.102E-05

System slack Total utilisation

2401.2% 2.68%

Table 3: Rate Monotonic analysis results for FPS

21 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

Table 3 ﬁrst shows the WCET of the tasks as deﬁned in the MAST model and which are controlled by the Whetstone workloads. Then the results of the analysis are displayed, containing the worst-case response time R max , the slack, the blocking time and the jitter for each transaction. The MAST analysis tool provides also best-case response times R min , but Rate Monotonic is a pessimistic analysis which assumes worst-case scenario at the critical instant, therefore only worst-case response time matters.

All transactions suffer jitter due to the system ticker interrupt running at the highest interrupt priority and the context switch overhead.

• regular_producer: suffers additional jitter due to the system clock with granularity 1ms and the possible execution of the interrupt handler. Its blocking time is caused by the On_Call_Producer and the Activation_Log_Reader which have lower priorities but can access resources with higher ceiling priority than Regular_Producer;

• ocp_transaction: suffers additional jitter due to interference by Regular_Producer. Its blocking time is caused the Activation_Log_Reader.;

• alr_transaction: suffers additional jitter due to interference by On_Call_Producer and Regular_Producer. It has no blocking time since it’s the task with lowest priority;

• interrupt_transaction: it’s the software level handler of the interrupt. It suffers no additional jitter other than the aforementioned overheads. Its blocking time is caused by the Activation_Log_Reader;

We shall now increase the Whetstone workload of factor 24 in the ﬁrst three transactions, since 2477.0% is the smallest slack of the three of them. The factor correponds to how much the execution time of all event responses can be increased while preserving system schedulability [28]. We leave the interrupt_transaction intact because it doesn’t contain any Whetstone operation. The new results are as shown in table 4.

Task

WCET

regular_producer on_call_producer activation_log_reader

0.482597

0.177482

0.088702

Transaction

R max

Slack

Worst blocking time

Jitter

rp_transaction ocp_transaction alr_transaction interrupt_transaction

0.485486 2.73%

0.662657 76.95%

0.751706 277.34%

2.102E-05 >=100000.0%

2.000E-06

1.000E-06

0.00

1.000E-06

0.002889

0.485175

0.663004

1.102E-05

System slack Total utilisation

3.21%

57.52%

Table 4: Rate Monotonic analysis results for FPS increased of factor 24

The blocking times have not changed because protected operations are same as before, but the total utilisation have increased up to 57.52%. The 2.73% slack value of Regular_Producer is already very low so we can leave it as it is. We proceed instead to increase the workload of On_Call_Producer and Activation_Log_Reader from factor 24 to 43 = 24 ∗ 1.77, using the slack value 77%.

Task

WCET

regular_producer on_call_producer activation_log_reader

0.482597

0.312341

0.156086

Transaction

R max

Slack

Worst blocking time

Jitter

rp_transaction ocp_transaction alr_transaction interrupt_transaction

0.485486 0.390625%

0.798039 0.390625%

0.954730 28.13%

2.102E-05 15421.1%

2.000E-06

1.000E-06

0.00

1.000E-06

0.002889

0.485698

0.798644

1.102E-05

22 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

System slack Total utilisation

0.390187%

64.26%

Table 5: Rate Monotonic analysis results for FPS increased of factor 43

The system has reached utilisation 64.26%. We now increase workload of Activation_Log_Reader from factor 43 to 55 = 43 ∗ 1.28, using the slack value 28%.

Task

WCET

regular_producer on_call_producer activation_log_reader

0.482597

0.312341

0.198645

Transaction

R max

Slack

Worst blocking time

Jitter

rp_transaction ocp_transaction alr_transaction interrupt_transaction

0.485492 0.0%

0.798039 0.390625%

0.997454 0.390625%

2.102E-05 15421.1%

2.000E-06

1.000E-06

0.00

1.000E-06

0.002889

0.485698

0.798809

1.102E-05

System slack Total utilisation

0.390187%

65.68%

Table 6: Rate Monotonic analysis results for FPS increased of factor 55

The maximum utilisation reached is about 65.68%. The only transaction with signiﬁcant slack left is interrupt_transaction, but tests show that an increase of the WCET of factor 154 in the operation external_event_server would improve the utilisation only up to 65.71%, hence we can ignore it.

6.2 Adding offsets

So far, tasks have been assumed to be scheduled independently, there are no relationships between the release of any pair of tasks. Consequently, the worst-case task release pattern has been assumed in the critical instants [12]; the resulting analysis is therefore sufﬁcient for any task release pattern. It may, however, be advantageous to specify timing constraints on release patterns. We try to include time offsets into the computational model and, by taking account of time offsets, we try to reduce the pessimism when bounding the timing behaviour of the system.

By assuming all tasks are independent, the current analysis is subject to two pessimistic points:

1. Critical instant: for tasks with offsets, we must take into account that the critical instant may not include the simultaneous activation of all higher priority tasks, as it was the case when all tasks were independent. The existence of offsets makes it impossible for some sets of tasks to simultaneously become active [36];

2. Blocking time: offsets can be used to avoid the need for a dynamic concurrency control protocol for access to shared resources. Two tasks in the same transaction may not need to use locks to guard access to a shared resource if certain constraints on response times and offsets hold [37].

The above pessimism can be avoided by modeling the precedence constraint: within a pair of tasks, one of them must complete execution before the other can be permitted to commence. If it can be shown that two tasks execute in exclusion then any resources shared exclusively between these tasks need not be guarded by locks, the tasks are guaranteed never to access the shared resource concurrently. Besides, the two tasks cannot be active concurrently, which means that neither task can be permitted to preempt the other causing interference in the critical instant.

6.2.1 Critical instant

Offsets can be used to express precedence contraints: the existence of offsets makes it impossible for some sets of tasks to simultaneously become active. This is achieved by "spreading out" the computation of tasks so that all the tasks are not released together.

In our system, the task On_Call_Producer (OCP) is actually not truly sporadic given that it’s activated by the Regular_Producer (RP) every 3 jobs. The two tasks are not thus independent and both the RP job which activates OCP

23 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

and the latter should belong to the same transaction. Equivalent argument holds true for the RP job that awakens Activation_Log_Reader (ALR). The remaining instances of the RP tasks should belong to another transaction again.

Formally, for the two tasks RP and OCP that are members of the same transaction, task RP must complete before task OCP is run. We have in theory two possible priority situations: task RP is of higher priority, or task OCP is of higher priority. Fortunately, in our system RP is the one of higher priority, which means that task OCP (of lower priority) will simply not execute if task RP has been released before task OCP and has remaining computation. It can be seen that the condition for the precedence constraint to be met is [37]:

Φ

RP

+ J RP ≤ Φ OCP

Otherwise, where task D is of higher priority, we cannot use the priority mechanism to ensure precedence, and must rely on offsets. Therefore, for the precedence relation to hold, the latest ﬁnish time of task C must be before the earliest release time of task D, i.e.:

O

C

+ r c < O D , where r c is the response time of C

MAST Offset-based analysis tools are able to derive such conditions from the following representations of the the newly described transactions.

Figure 14: Transaction A

The transaction A has a period of 3, representing the stand-alone RP instance.

Figure 15: Transaction B

Figure 16: Transaction C

The transactions B and C have also a period of 3 and include the RP job which activates the OCP and ALR jobs respectively. Both transactions have an initial offset from the external periodic event to differentiate each RP instance from the others.

The unfolding of the three transactions reproduces the timeline in Figure 17, assuming the Whetstone values reached by the previous analysis. It is clear from the timeline that there is possibility for the OCP and ALR jobs to further expand their executions without provoking any deadline miss. Nevertheless, the pessimistic Rate Monotonic analysis returns zero slack because of the possible interference between stand-alone tasks.

As can be seen below, the Offset Based Slanted analysis provides an improvement of the best response times. Offsetbased analysis tools are able to consider the offset values so that chained tasks are not released together.

Task

WCET

regular_producer on_call_producer activation_log_reader

0.482597

0.312341

0.198645

Transaction

R min

R max

Slack

Worst blocking time

Jitter

24 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

transaction_a transaction_b RP transaction_b OCP transaction_c RP transaction_c ALR interrupt_transaction

0.482597 1.454

1.483 2.454

1.795 3.737

2.483 3.454

2.681 4.936

1.000E-05 2.102E-05

-66.02% 2.000E-06

-66.02% 2.000E-06

-66.02% 1.000E-06

-66.02% 2.000E-06

-66.02% 0.00

-100.0% 1.000E-06

0.971820

0.971820

1.942

0.971820

2.255

1.102E-05

System slack Total utilisation

-65.55% 65.68%

Table 7: Offset Based Slanted analysis results

Both the R min and R max response times produced by the analysis include the initial offsets of the transaction, but the former RP R min values are also used as offset Φ ij of the dependant tasks OCP and ALR for their respective response times. The R max values are instead the sum of the corresponding R min and jitter.

Between R min and R max response times, we consider only the best-case response time R min . The timeline in Figure 17 clearly shows that the three transactions have the same source of activation, a RP job, and there is no interference between tasks. Thus there cannot be any signiﬁcant jitter and only the R min value is valuable for our considerations since it already takes into account the offsets and examines the actual case with zero interference. Besides, by not considering the worst-case response times, we ignore the slack values as well. If the best-case response time is within the deadline then it’s sufﬁcient for our considerations.

Task

WCET

regular_producer on_call_producer activation_log_reader

0.482597

0.312341

0.198645

Transaction

R min

R max

Slack

Worst blocking time

Jitter

transaction_a transaction_b RP transaction_b OCP transaction_c RP transaction_c ALR interrupt_transaction

0.482597 1.454

1.483 2.454

1.795 2.768

2.483 3.454

2.681 3.967

1.000E-05 2.102E-05

-66.02% 2.000E-06

-66.02% 2.000E-06

-66.02% 1.000E-06

-66.02% 2.000E-06

-66.02% 0.00

-100.0% 1.000E-06

0.971820

0.971820

0.973028

0.971820

1.286

1.102E-05

System slack -65.55% Total utilisation 65.68% Table 8: Offset Based Approximate with Precedence Relations analysis results

Compared to Offset Based Slanted, Offset Based Approximate with Precedence Relations analysis is able to provide even tighter worst-case response times by using the precedence relation and therefore considering a dynamic offset Φ i2 ∈ [R ISR min , R ISR max ]. I.e. the OCP task is never activated before the RP completion, therefore its jitter can be approximately reduced to J B,OCP = J B,RP .

Future analysis in this section will provide only the results from the Offset Based Approximate with Precedence Relations technique, referred only as Offset-based analysis, as it has proved to be the best of the two tools even if are interested only in best-case response times.

6.2.2 Blocking time We can further improve the analysis by reducing unnecessary blocking time: the precedence constraint between the RP and OCP means the former cannot suffer blocking time from the latter. There is also no need to use any lock to guard the access to the Request_Buffer resource given that concurrent access is not possible.

By removing the resource lock on Request_Buffer, we obtain the results in table 9 for the three transactions.

The IPCP ensures the each task can be blocked at most once, at its beginning, by a single lower-priority task [5]. Then the removal of the lock on Request_Buffer reduces the maximum blocking time suffered the tasks to a value equal to the execution time of the lowest priority Activation_Log_Reader within the shared resource Activation_Log.

25 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

Figure 17: Unfolded timeline

Task

WCET

regular_producer on_call_producer activation_log_reader

0.482597

0.312341

0.198645

Transaction

R min

Worst blocking time

Jitter

transaction_a transaction_b RP transaction_b OCP transaction_c RP transaction_c ALR interrupt_transaction

0.482597 1.000E-06

1.483 1.000E-06

1.795 1.000E-06

2.483 1.000E-06

2.681 0.00

1.000E-05 1.000E-06

0.971820

0.971820

0.973028

0.971820

1.286

1.102E-05

Total utilisation 65.68% Table 9: Offset-based analysis without request_buffer

A further in-depth analysis is presented later in Section 7.4, which gathers the observations for both FPS and EDF blocking times actually suffered by our application..

6.2.3 Maximum utilisation Leveraging the newly deﬁned offset-based model, we can try to achieve maximum system utilisation. By having a look at the unfolded timeline in Figure 17, it is evident that RP has already reached its maximum workload, but OCP can still increase up to approximately 0.5s and likewise ALR. Bearing in mind the possible jitter caused by the system ticker (0.5/0.001 ∗ 3.844E − 06 = 0.001922), both tasks can raise their execution time way to 0.5 − 0.001922 = 0.498078.

Actually, compared to the Rate Monotonic Analysis, RP can be increased by a tiny amount to get the WCET up to 0.5s as well. The ﬁnal offset-based FPS analysis with maximum utilisation is displayed in Table 10.

All the best-case response times are within the deadlines and the concluding maximum utilisation, with proven runtime feasibility, of the FPS system is approximately 83.28%. If we ﬂatten the ﬁnal transactions onto a single timeline, we obtain Figure 18. Within the hyperperiod of 3 seconds, or equivalently 6 blocks of 0.5seconds, there is only a single block of 0.5s of task idleness. The theoretical utilisation is then 5/6 = 0.8¯3%, very close to the value provided by the MAST analysis.

Figure 18: Flattened timeline

P Analytically the system utilisation is approximately i∈{RP,OCP,ALR} C T i i = 0.5 1 + 0.5 3 + 0.5 3 = 5 6 . Runtime overhead, such as system ticker or context switch, and also blocking times have been left out the formula given that they are

negligible in the approximation.

26 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

Task

WCET

regular_producer on_call_producer activation_log_reader

0.496961

0.497936

0.497844

Transaction

R min

Worst blocking time

transaction_a transaction_b RP transaction_b OCP transaction_c RP transaction_c ALR interrupt_transaction

0.497003 1.000E-06

1.497 1.000E-06

1.995 1.000E-06

2.497 1.000E-06

2.995 0.00

1.000E-05 1.000E-06

Total utilisation 83.28% Table 10: Offset-based analysis with max utilisation

7

EDF Analysis

The Earliest Deadline First (EDF) [19] scheduling is dynamic-priority algorithm that assigns priorities to individual jobs of a task based on its absolute deadline. In particular, the earlier the deadline, the higher the priority. The absolute deadline of a job is computed as the sum of its release event plus its relative deadline. Such relative deadline is a static attribute, missing in FPS algorithm and corresponding to the maximum response time allowed to each task instance.

The runtime we have adopted is an Ada Ravenscar runtime variant implementing an EDF scheduling coupled with the Deadline Floor Protocol (DFP) [42] as resource locking polocy.

DFP is the EDF counterpart of the Immediate Priority Ceiling Protocol (IPCP), outlined in Section 1.2. Indeed, rather than assigning a ceiling priority to each shared resource r i , a deadline ﬂoor value D i is computed as the minimum relative deadline of any task accessing such resource.

Besides, instead of raising the priority of a task to the resource’s ceiling, when a task τ i released at time s accesses resource r i at time t (so s < t) its relative deadline is immediately reduced to D i . As a result, its active absolute deadline d i is also (potentially) reduced to d i ← min{t + D i , s + D i }. Finally, when the task frees the resource its deadline immediately returns to its original value.

Clearly, the IPCP for ﬁxed-priority systems and DFP for dynamic-priority systems are structurally equivalent. FPS uses a ceiling value as dispatching urgency, whereas a ﬂoor value is expected as earlier deadline under EDF.

7.1 A MAST model for EDF

Unfortunately, as mentioned in Section 5.2, MAST requires even stricter restrictions for EDF analysis tools than FPS. The Offset-based analysis is not yet available for EDF at the time of writing, and rollbacks to the Holistic analysis, which in turn does not yet support shared resources. Therefore, we had to discard both Offset-based and Holistic analisys tools.

The last standing option was the EDF Monoprocessor tool, which implements the exact response time analysis for single-processor in EDF systems. Unfortunately, the Simple_Transaction_Only restriction (§5.2) forbids deﬁnining a transaction comprising a sequence of activities executed by different Execution Servers. Hence, dependency contraints between the task releases could not be expressed.

In addition, the EDF Monoprocessor analysis is able to support only Stack Resource Policy (SRP) [42] as resource access protocol. Under SRP, each job is assigned a preemption level π(τ i ) inversely proportional to the task relative deadline D i , e.g. π(τ i ) < π(τ j ) ⇔ D i > D j .

In turn, each resource is assigned a ceiling preemption level Π(r i ) deﬁned as the maximum preemption level of any job that may access it. After deﬁning the system ceiling πˆ as the highest ceiling of all the resources which are held by some job at any time t, the following deﬁnition of the SRP locking policy is provided. A job j i released at time t can start execution only if:

• the absolute deadline of this job (t + D i ) is the earliest deadline of the active requests in the task set;

• its preemption level is higher than the system ceiling π(r i ) > πˆ .

27 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

Nevertheless, the disparity in resource access control protocols between runtime implementation and MAST can be ignored because of the worst-case bound equivalence between SRP and DFP [42]. Indeed they lead to even the same worst blocking time analysis.

As a result, within the MAST model, we must provide the preemption level for each task according to the SRP. An available assignment is displayed in Table 11.

Task name

Deadline (ms)

Preemption Level

External_Event_Server Regular_Producer On_Call_Producer Activation_Log_Reader

100 500 800 1000

40 30 20 10

Table 11: Preemption Levels for the task set

According to the newly deﬁned preemption levels, Table 12 shows a correct deﬁnition of the resource ceilings.

Resource name

Ceiling Preemption Level

Request_Buffer Activation_Log Event_Queue

30 40 50

Table 12: Ceiling Preemption Levels for the resource set

7.2 EDF Monoprocessor analysis

The EDF Monoprocessor tool is based on the formal analysis developed by Spuri [39], which considers the busy period to study the feasibility of the schedule. As depicted in Figure 19, the worst case response time (WCRT) of a task τ i is found in a busy period [t 1 , t 2 ] in which all other tasks are released synchronously at t = 0 and then at their maximum rate. Such busy period is characterized by the job j i released at time t = a, a ≥ 0, preceded by other jobs of any task which do not let the CPU idle, possible by other instances of task τ i itself. t 1 is the the ﬁrst instant preceding the release of j i without CPU idleness, whereas t 2 is the completion time of the job i under consideration.

Figure 19: Busy period (a) leading to the job j i WCRT (b) [39]

With this being said, the transactions of this model are exactly those in the FPS model with independent task set as outlined in §6.1. Thus we still have four transaction, each one composed of a single activity.

28 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

As workload values, we have set the best values reached by the Offset-based analysis and fed the model to the EDF Monoprocessor analysis to compare the two tools. The results for the latter are pasted in Table 13.

Task

WCET

regular_producer on_call_producer activation_log_reader

0.496961

0.497936

0.497844

Transaction

R max

Slack

Worst blocking time

Jitter

rp_transaction ocp_transaction alr_transaction interrupt_transaction

0.992883 -99.22%

1.293 -99.22%

1.493 -100.00%

0.592882 -100.00%

2.000E-06

2.000E-06

2.000E-06

1.000E-06

0.495880

0.794917

0.995006

0.592872

System slack Total utilisation

-32.98% 82.90% Table 13: EDF monoprocessor analysis results

As expected, this is an unfair comparison because a busy period in which all tasks but one are released synchronously leads to a great pessimism in the worst case response time. Figure 20 presents the worst arrival pattern considered by MAST to cause the WCRT of Regular_Producer. However, because of the dependencies between release events, RP will never compete for the CPU with ALR because it is completion of the former with provokes the release event of latter and without overloading the two tasks are never active simultaneous.

Figure 20: Busy period leading to RP’s WCRT

A more fair comparison would pick Rate Monotonic analysis as the FPS counterpart as response time analysis tool for single-processor, since both assume tasks to be standalone. Indeed, providing the best workloads achieved previously via Rate Monotonic, EDF Monoprocessor prints the results in Table 14. The slack values are close to the previous FPS results and the reason can be found again in Figure 20. Assuming this pessimistic case, no further signiﬁcant improvement can be made to any task workload without missing a deadline.

We believe instead that the slight slack improvement is due to the absence of the system ticker in EDF analysis, that is it doesn’t take into account the possible release jitters and interferences suffered by each task.

To sum up, MAST can ensure a relatively poor utilisation under EDF scheduling because we aren’t allowed to maintain consistency between model and application. We may question what is the real performance granted by such dynamic-scheduling.

29 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

Task

WCET

regular_producer on_call_producer activation_log_reader

0.482555

0.312311

0.198612

Transaction

R max

Slack

Worst blocking time

Jitter

rp_transaction ocp_transaction alr_transaction interrupt_transaction

0.494969

0.794969

0.993620

0.094968

0.781250%

1.56%

3.13% 41928.5%

2.000E-06

2.000E-06

2.000E-06

1.000E-06

0.012372

0.482628

0.794975

0.094958

System slack Total utilisation

0.783430%

65.29% Table 14: EDF Monoprocessor analysis results

7.3 Runtime behaviour

Despite the pessimistic MAST analysis results, EDF is an optimal scheduler and can handle a theoretic total utilization up to 1. In addition, any feasible preemptive FPS schedule can be transformed into an EDF schedule without affecting its feasibility [39]. Hence, we expect the EDF runtime to perform at least as well as the FPS counterpart under the maximum workload reached with Offset-based analysis §6.2.3.

Figure 21: Application execution under EDF scheduling with maximum utilisation

Figure 21 exhibits the schedule produced by EDF up to the hyperperiod H = 3. The total utilisation of 83.28% is given by the Whetstone values in Table 15.

Task

WCET

regular_producer on_call_producer activation_log_reader

0.496961

0.497936

0.497844

Table 15: Whetstone values leading to maximum FPS and EDF utilisation

30 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

Despite the EDF optimality, by observing the aforementioned timeline, there is unfortunately no room for utilisation increase. RP already runs at zero laxity, whereas OCP and ALR cannot exceed an execution time of 0.5 seconds without causing a fatal release jitter to RP itself.

This is further proved by noting that both EDF and FPS algorithms lead to same schedule of our application, under the condition that no tasks misses its deadline. FPS assigns priorities inversely proportional to the relative deadline D i , whereas EDF calculates them inversely proportional to the absolute deadline d i . In general, the relation D i < D j ⇔ d i < d j does not hold, but in our speciﬁc case we can demonstrate it’s valid.

Given a pair of task τ i and τ j , for the task τ i with relative deadline D i > D j to have absolute deadline d i < d j it must be released at time t i < t j , i.e. for OCP to have a lower absolute deadline than RP. But under the condition that no task overruns, this situation is clearly not possible. Both OCP and ALR are always activated by the RP and they complete before the next release of RP. This proves that, within our application with precedence relations, D i < D j ⇔ d i < d j and therefore both algorithms assign the same priority.

7.4 Blocking Time

A further consideration can be made about the blocking time by reasoning with the timeline in Figure 21. The blocking time suffered by each job is equal to zero, except for one case, for that no higher-priority job will be suspended waiting for a lower-priority job to complete its use of a (non-preemptable) resource.

Since DFP is structurally equivalent to IPCP, there are two kinds of possible blocking [5].

1. Direct blocking, a situation in which a higher priority task is blocked by a lower-priority task which accesses a resource shared between the two of them. In our application, this may happen only between ALR and External_Event_Server (EES), which have indipendent release events. Direct blocking cannot happen between RP and OCP, again because they are never simultaneously active;

2. Push-through blocking happens when a medium priority task can be blocked by a lower priority task, which inherits the priority of a high priority task. In our analysis, the only plausible case would be RP being pushblocked by ALR, which receives the priority of EES. However, since ALR is activated when RP terminates and vice versa, this situation cannot happen between the two tasks.

Because of the comparability between PCP and DFP and the schedule correspondence between FPS and EDF with our taskset, the aforementioned observations about the blocking time can be made also for the ﬁxed-priority application.

8

Overloading

A job is said to overrun when it executes for more than its guaranteed execution time. We say that a system is overloaded when it is not schedulable on the basis of the maximum execution times of its tasks and hence it is likely that some jobs will miss their deadlines [40].

Any algorithm for scheduling jobs with a potential for overrun should meet two criteria if it is to perform well. First, it should guarantee that jobs which do not overrun meet their deadlines and, second, the algorithm try to maximize the number of deadlines met.

In this section, we compare the behaviour of our application under FPS and EDF during permanent overload situations, which occurr in literature when the system utilisation U > 1. In our case, our limit is not the theoretical full CPU utilisation 1, we have seen we should consider 0.83 as limits for both FPS and EDF.

8.1 FPS overloading

When tasks have ﬁxed priorities, overruns of jobs in a task can never affect higher-priority tasks and it is possible to predict which tasks will miss their deadlines during an overload. Likewise, another equivalent point of view is that a permanent overload may cause a complete blocking of the lower priority tasks.

We have observed this behaviour in our tests by increasing the RP workload of a small amount  = 0.02s, reaching a WCET of approximately 0.52s.

Interrupt generated Deadline Miss Detected End of cyclic activation. Deadline Miss Detected -

RP

RP

31 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

End of cyclic activation. Deadline Miss Detected - OCP Deadline Miss Detected - RP End of cyclic activation.

End of sporadic activation. Deadline Miss Detected - RP End of cyclic activation. Deadline Miss Detected - ALR End of parameterless sporadic

activation.

1

Figure 22: Timeline with overruning RP As proved by the runtime log and shown in the timeline in Figure 22, an overruning RP affects all the lower-priority tasks and causes their deadline miss as well.

Interrupt generated End of cyclic activation.

End of cyclic activation. Deadline Miss Detected - OCP End of cyclic activation. Elapsed time: 0.530376517 End of sporadic activation. End of cyclic activation. Deadline Miss Detected - ALR End of parameterless sporadic

activation.

1

Figure 23: Timeline with overruning OCP Runtime log and Figure 23 show that an overload of OCP never impacts the higher-priority task RP which can meet all its deadlines. ALR will instead miss its deadline once again.

32 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

8.2 EDF overloading

In literature, the EDF exhibits an unstable behaviour during an overload: a late EDF job which has already missed its deadline has a higher-priority than a job whose deadline is still in the future. Consequently, if the execution of a late job is allowed to continue, it may cause the other jobs to be late.

Interrupt generated Deadline Miss Detected - RP End of cyclic activation. Deadline Miss Detected - RP End of cyclic activation.

End of sporadic activation. Deadline Miss Detected - RP End of cyclic activation. Deadline Miss Detected - RP End of cyclic activation. Deadline Miss Detected - ALR End of parameterless sporadic

activation.

1

Figure 24: Timeline with overruning RP in EDF

A RP overload of  = 0.02s causes the deadline miss of the ALR, as shown in the runtime log and Figure 24, but OCP seems to meet its deadline nevertheless. This behaviour is apparently in contrast with the FPS overload with the same overruning task. However, if we consider a more signiﬁcant overrun of  = 0.2 and expand the timeline beyond the hyperperiod, an interesting pattern emerges.

Figure 25: Extended timeline with overruning RP in EDF

All OCP jobs, except for the ﬁrst instance, fail to meet the deadline and a regular pattern comprising the three tasks emerges as soon as the timeline goes beyond time instant 4. This peculiar EDF behaviour where there is an initial period of irregularity followed by regular executions and events is not exhibited by the analogous FPS algorithm with RP overruning of the same amount. In ﬁxed-priority scheduling, all jobs miss their deadline and the regularity emerges from the ﬁrst instant of execution.

When the ﬁrst task that misses its deadline causes all subsequent tasks to miss their deadlines, the effect is called the domino effect [45]. EDF is prone to the domino effect and it rapidly degrades its performance during overload intervals. This is due to the fact that EDF gives the highest priority to those processes that are close to missing their deadlines. Even worse, we note that a late job which has already missed its deadline has a higher-priority than a job whose deadline is still in the future [19].

33 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

Figure 26: Extended timeline with overruning RP in FPS

The application under consideration doesn’t seem to provoke domino effect. Although a permanent overload of RP causes all subsequent tasks to miss their deadline, it’s trivial to show with a timeline that a transient overload of it causes a ﬁnite amount of following deadline misses then the system recovers. The same property holds for an overruning OCP, as made clear by Figure 27. We believe this is again because of the precedence relationships. Even if RP misses a deadline, the later OCP and ALR are not activated indipendently. They wait for RP completion and are more difﬁcult subject to domino effect.

Nevertheless, a difference between FPS and EDF is that, under the former, a transient overrun in task cannot cause tasks with higher priority to miss their deadlines, whereas under EDF any other task could miss its deadline. That is, the latter does not provide any type of guarantee on which tasks will meet their timing constraints.

Figure 27: Timeline with overruning OCP in EDF

9

Conclusions

We have started off the analysis by seeing the uses of offsets as a mechanism to improve the consistency between a formal model and the runtime execution of a real-time application subject to precedence relations. In turn, this has helped to reduce the pessimism in the ﬁxed-priority analysis and offsets have proved to be extremely useful in increasing the schedulability of a given task set.

Throughout this paper, we have used MAST as model for describing real-time applications and representing not only the characteristics of the architecture of the application, but also the hard real-time requirements that are imposed. However, we believe there is still some scheduling theory needed to eliminate some of the restrictions. The combination of all the restrictions have posed a serious blocking issue in our ability to describe a consistent model which could lead to a sound analysis of maximum utilisation. From our experience, the most important missing pieces the enhancement of the offset-based event analysis between transactions, to make it less pessimist, and the support for EDF offset-based analysis of linear transactions.

Besides, in this paper we compared the behavior of the two most famous policies: the FPS and the EDF algorithm. EDF allows a theoretic full processor utilization, which implies a more efﬁcient exploitation of computational resources but the statement doesn’t hold in general with applications composed of dependant tasks.

At the same time, predictability during overload conditions only apply for the highest priority task, and it is not valid in general for the other tasks. Such a property of FPS can be of little use if we do not know a priori which other task is going to overrun [43]. Under permanent overload conditions, both the behaviors of FPS and EDF are predictable except for an initial interval, but deciding which one is better is highly application conditional. Nevertheless, what we have presented in this paper is just a shallow insight. Further work is surely needed to better explore the implications of relation dependencies in FPS and EDF overload.

34 MAST analysis of a Ravenscar precedence-constrained application with FPS and EDF scheduling

In this paper, we have also introduced the Deadline-Floor Protocol for controlling access to shared resources within the EDF scheduling framework. This protocol has already been proved to equivalent to the Stack Resource Protocol, the defacto protocol to use with EDF, by A. Burns (2005) [42]. We have instead shown that the combination EDF+DFP can exhibit the same schedule and blocking times of FPS+IPCP in system where job releases are not stand-alone but rather form a chain.

Indeed, we believe that the implications of precedence constraints are worth to be the subject of further research.
